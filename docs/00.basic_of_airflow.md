# Basic of Airflow

## 1. What is Airflow?

- 오픈소스 기반 **Workflow 관리 도구** (Python 기반)
- 스케줄링 + 의존성 관리 + 실행 상태 관리
- DAG(Directed Acyclic Graph)로 작업 정의
- Cron 기반 스케줄링 지원
- 모니터링 및 실패 재처리 기능

> Airflow는 작업을 직접 실행하지 않고, **작업 실행 순서를 관리하는 오케스트레이터**이다.

---

## 2. Core Concepts

### 2.1 DAG (Directed Acyclic Graph)

- Task들의 집합과 실행 순서를 정의한 단위
- 특징:
  - 방향성 있음 (A → B)
  - 순환 불가능 (A → B → C → A 불가)
  - 하나의 DAG = 하나의 Workflow

### 2.2 Task

- DAG 내의 **실행 단위**
- 상태: `success`, `failed`, `running`, `skipped`
- 개별 재실행 가능 (idempotent하게 설계해야 함)

### 2.3 Operator

- Task를 정의하는 **템플릿**
- 종류:
  - `PythonOperator` : Python 함수 실행
  - `BashOperator` : 쉘 명령어 실행
  - `DockerOperator` : Docker 컨테이너 실행
  - `EmailOperator` : 이메일 발송
  - Sensor : 조건 대기 (아래 참고)

### 2.4 Sensor

- 조건이 충족될 때까지 **대기**하는 특수 Operator
- 종류:
  - `FileSensor` : 파일 생성 대기
  - `S3KeySensor` : S3 업로드 대기
  - `HttpSensor` : HTTP 응답 대기

### 2.5 Dependencies (작업 의존성)

Task 간 순서 정의:

```python
# 순차 실행: A → B → C
task_a >> task_b >> task_c

# 병렬 실행: A, B, C 모두 완료 후 D 실행
[task_a, task_b, task_c] >> task_d
```

---

## 3. Architecture

### 3.1 Scheduler

- DAG 파일을 읽고 실행 시점 계산
- 실행 대상 Task를 Executor에 전달
- 상태 모니터링

### 3.2 Executor

Task 실행 방식 결정:

| Executor | 용도 |
|---|---|
| `SequentialExecutor` | 개발/테스트 (순차 실행) |
| `LocalExecutor` | 소규모 환경 (병렬 실행) |
| `CeleryExecutor` | 대규모 환경 (분산 실행) |
| `KubernetesExecutor` | 클라우드/K8s 환경 |

### 3.3 Worker

- 실제 Task를 실행하는 프로세스
- `CeleryExecutor`에서 여러 Worker가 병렬 처리

### 3.4 Metadata Database

- 모든 실행 상태 저장 (SQLite 또는 PostgreSQL)
- 저장 정보: DAG 기록, Task 상태, 재시도 정보 등

### 3.5 Web UI

- URL: `http://localhost:8080`
- DAG 시각화, 실행 로그, 수동 실행

---

## 4. Execution Model

### 4.1 Logical Date (Execution Date)

실제 실행 시각이 아닌, **스케줄 주기를 대표하는 날짜**

```
DAG 설정: 매일 00:00 실행, start_date=2025-02-16
물리 실행 시각: 2025-02-17 00:00
→ logical_date: 2025-02-16 (16일치 데이터를 처리한다는 의미)
```

템플릿에서 접근:
```python
{{ ds }}              # "2025-02-16"
{{ logical_date }}    # datetime 객체
```

### 4.2 Catchup

과거 누락된 스케줄을 자동 실행할지 결정:

```python
dag = DAG(
    dag_id="example",
    start_date=datetime(2025, 1, 1),
    schedule="@daily",
    catchup=False,  # False: 현재부터만 실행 / True: 과거분 모두 실행
)
```

### 4.3 Backfill

과거 특정 날짜 범위를 수동 재실행:

```bash
airflow dags backfill -s 2025-01-01 -e 2025-01-31 example_dag
```

---

## 5. Retry & Failure Handling

> Airflow는 모든 Task가 실패할 수 있다고 가정하고 설계됨

### 5.1 기본 Retry 설정

```python
PythonOperator(
    task_id="example_task",
    python_callable=run_job,
    retries=3,                        # 최대 3회 재시도
    retry_delay=timedelta(minutes=5), # 5분 대기 후 재시도
)
```

### 5.2 DAG 단위 기본값

```python
default_args = {
    "retries": 3,
    "retry_delay": timedelta(minutes=5),
}

dag = DAG(
    dag_id="example",
    default_args=default_args,
    ...
)
```

### 5.3 Trigger Rules

Task 실행 조건 정의:

```python
PythonOperator(
    task_id="task_c",
    python_callable=some_func,
    trigger_rule="all_success",  # 모든 선행 Task 성공
    # trigger_rule="all_failed",  # 모든 선행 Task 실패
    # trigger_rule="one_success", # 1개 이상 성공
)
```

---

## 6. XCom (Cross Communication)

Task 간 데이터 전달:

```python
# Task A에서 데이터 반환 (자동 저장됨)
def task_a(**context):
    return {"data": "Hello"}

# Task B에서 데이터 가져오기
def task_b(**context):
    result = context["task_instance"].xcom_pull(task_ids="task_a")
    print(result)  # {'data': 'Hello'}
```

> XCom은 작은 메타데이터용. 대용량은 S3, 공유 스토리지 사용.

---

## 7. Connection & Variables

### Connection: 외부 시스템 연결 정보
- Web UI → Admin → Connections에서 관리
- 데이터베이스, API, 클라우드 서비스 인증

### Variables: 전역 변수
- Web UI → Admin → Variables에서 관리
- DAG/Task 공통 설정값

```python
from airflow.models import Variable

batch_size = Variable.get("batch_size", default_var=1000)
```

---

## 8. 간단한 ETL 예제

```python
from datetime import datetime, timedelta
from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator

default_args = {
    "owner": "data_team",
    "retries": 2,
    "retry_delay": timedelta(minutes=5),
}

dag = DAG(
    dag_id="simple_etl",
    default_args=default_args,
    start_date=datetime(2025, 1, 1),
    schedule="@daily",
    catchup=False,
)

def extract(**context):
    print("Extracting data...")
    return {"rows": 1000}

def transform(**context):
    data = context["task_instance"].xcom_pull(task_ids="extract")
    print(f"Transforming {data['rows']} rows...")
    return {"processed_rows": data["rows"]}

def load(**context):
    data = context["task_instance"].xcom_pull(task_ids="transform")
    print(f"Loading {data['processed_rows']} rows...")

extract_task = PythonOperator(task_id="extract", python_callable=extract, dag=dag)
transform_task = PythonOperator(task_id="transform", python_callable=transform, dag=dag)
load_task = PythonOperator(task_id="load", python_callable=load, dag=dag)

extract_task >> transform_task >> load_task
```

---

## 9. Best Practices

1. **Task는 멱등성(Idempotent)하게** - 같은 입력 → 항상 같은 결과
2. **작은 Task로 분할** - 실패 시 재시도 범위 최소화
3. **충분한 로깅** - 문제 추적 용이
4. **timeout 설정** - 무한 대기 방지
5. **alert 설정** - 실패 시 알림

---